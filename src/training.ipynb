{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import logging\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "data_logger = logging.getLogger(\" DATA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "we are using `data0` and `data1` for training, and `data2` for testing. This setup allows us to train our model on a diverse set of data and evaluate its performance on a separate test set to ensure generalization.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Data processing\n",
    "\n",
    "def load_data():\n",
    "    img_data_0 = np.load('../data/data0.npy')\n",
    "    img_data_1 = np.load('../data/data1.npy')\n",
    "    img_data_2 = np.load('../data/data2.npy')\n",
    "    img_label0 = np.load('../data/lab0.npy')\n",
    "    img_label1 = np.load('../data/lab1.npy')\n",
    "    img_label2 = np.load('../data/lab2.npy')\n",
    "\n",
    "    xtrain = torch.tensor(np.concatenate((img_data_0, img_data_1)),dtype=torch.float32).unsqueeze(1)\n",
    "    xtest = torch.tensor(img_data_2,dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    ytrain = torch.tensor(np.concatenate((img_label0, img_label1)),dtype=torch.float32)\n",
    "    ytest = torch.tensor(img_label2,dtype=torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(xtrain, ytrain)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(xtest, ytest)\n",
    "\n",
    "    # Split the test set into validation and test sets\n",
    "    val_size = int(0.2 * len(xtest))\n",
    "    test_size = len(xtest) - val_size\n",
    "\n",
    "    val_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [val_size, test_size])\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    data_logger.info(\"Data loaded successfully\")\n",
    "    return {\n",
    "        \"train_dataloader\": train_dataloader,\n",
    "        \"test_dataloader\": test_dataloader,\n",
    "        \"val_dataloader\": val_dataloader,\n",
    "        \"train_dataset\": train_dataset,\n",
    "        \"test_dataset\": test_dataset,\n",
    "        \"val_dataset\": val_dataset,\n",
    "        \"xtrain\": xtrain,\n",
    "        \"xtest\": xtest,\n",
    "        \"ytrain\": ytrain,\n",
    "        \"ytest\": ytest\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! visualisation\n",
    "\n",
    "def visualize(test_dataloader,train_dataloader):\n",
    "    test_data_iter = iter(test_dataloader)\n",
    "    test_images, test_labels = next(test_data_iter)\n",
    "\n",
    "    # Plot the first 4 images in the batch\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 2.5))\n",
    "    for i in range(4):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(test_images[i].numpy().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {test_labels[i].item()}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "    # Iterate through the DataLoader\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        print(f\"Batch {i + 1}:\")\n",
    "        print(f\"  Input shape: {inputs.shape}\")\n",
    "        print(f\"  Labels shape: {labels.shape}\")\n",
    "        # Break after the first batch to limit output (optional)\n",
    "        break\n",
    "    data_logger.info(\"Data visualisation done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logger = logging.getLogger(\"MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(1024)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Calculate the flattened size\n",
    "        self.fc1 = nn.Linear(1024*2*10, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 37) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = self.pool(F.relu(self.bn6(self.conv6(x))))\n",
    "\n",
    "        x = x.view(-1, 1024*2*10)  # Use dynamically computed size\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Swish activation function\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Squeeze-and-Excitation block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduced_dim):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, reduced_dim, kernel_size=1),\n",
    "            Swish(),\n",
    "            nn.Conv2d(reduced_dim, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "# MBConv block\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expand_ratio, stride, kernel_size, reduction_ratio=4, drop_connect_rate=0.2):\n",
    "        super(MBConv, self).__init__()\n",
    "        mid_channels = in_channels * expand_ratio\n",
    "        reduced_dim = max(1, in_channels // reduction_ratio)\n",
    "\n",
    "        self.expand = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False) if expand_ratio != 1 else None\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels) if expand_ratio != 1 else None\n",
    "        self.swish = Swish()\n",
    "        self.depthwise = nn.Conv2d(mid_channels, mid_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                   padding=kernel_size // 2, groups=mid_channels, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.se = SEBlock(mid_channels, reduced_dim)\n",
    "        self.pointwise = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.skip_connection = stride == 1 and in_channels == out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.expand:\n",
    "            x = self.swish(self.bn1(self.expand(x)))\n",
    "        x = self.swish(self.bn2(self.depthwise(x)))\n",
    "        x = self.se(x)\n",
    "        x = self.bn3(self.pointwise(x))\n",
    "        if self.skip_connection:\n",
    "            x += residual\n",
    "        return x\n",
    "\n",
    "# EfficientNet-like model\n",
    "class EfficientNetCustom(nn.Module):\n",
    "    def __init__(self, num_classes=37, dropout_rate=0.5):\n",
    "        super(EfficientNetCustom, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False),  # Adjusted for 1 input channel\n",
    "            nn.BatchNorm2d(32),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            MBConv(32, 32, expand_ratio=1, stride=1, kernel_size=3),\n",
    "            MBConv(32, 64, expand_ratio=6, stride=2, kernel_size=3),\n",
    "            MBConv(64, 128, expand_ratio=6, stride=2, kernel_size=5),\n",
    "            MBConv(128, 256, expand_ratio=6, stride=2, kernel_size=5)\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(256, 1280, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            Swish(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1280, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.head(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_params(self,device,net,data,optim=None,criterion=nn.CrossEntropyLoss()):\n",
    "        self.device = device\n",
    "        self.net = net\n",
    "        self.data = data\n",
    "        self.optim = optim\n",
    "        self.criterion = criterion\n",
    "        model_logger.info('Model Parameters Set')\n",
    "\n",
    "    def train(self, epochs=10, lr=0.001, patience=5):\n",
    "        self.net.to(self.device)\n",
    "        self.net.train()\n",
    "        self.optim = optim.Adam(self.net.parameters(), lr=lr) if self.optim is None else self.optim\n",
    "        model_logger.info('Start Training')\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "            running_loss = 0.0\n",
    "            val_running_loss = 0.0\n",
    "\n",
    "            # Training phase\n",
    "            self.net.train()\n",
    "            for i, data in enumerate(self.data[\"train_dataloader\"], 0):\n",
    "                inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                self.optim.zero_grad()\n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.criterion(outputs, labels.long())\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Validation phase\n",
    "            self.net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(self.data[\"val_dataloader\"], 0):\n",
    "                    inputs, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                    outputs = self.net(inputs)\n",
    "                    loss = self.criterion(outputs, labels.long())\n",
    "                    val_running_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = running_loss / len(self.data[\"train_dataloader\"])\n",
    "            avg_val_loss = val_running_loss / len(self.data[\"val_dataloader\"])\n",
    "\n",
    "            tqdm.write(f\"Epoch {epoch + 1} : Training Loss: {avg_train_loss} Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.net.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                model_logger.info('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "        model_logger.info('Finished Training')\n",
    "\n",
    "    def test(self):\n",
    "        self.net.to(self.device)\n",
    "        self.net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in self.data[\"test_dataloader\"]:\n",
    "                images, labels = data[0].to(self.device), data[1].to(self.device)\n",
    "                outputs = self.net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        model_logger.info(f'Accuracy of the network on the test images: {100 * correct / total}%')\n",
    "\n",
    "    def save_model(self,path):\n",
    "        torch.save(self.net.state_dict(), path)\n",
    "        model_logger.info('Model Saved')\n",
    "\n",
    "    def load_model(self,path):\n",
    "        self.net.load_state_dict(torch.load(path))\n",
    "        model_logger.info('Model Loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 11:23:32,912 -  DATA - INFO - Data loaded successfully\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x250 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 11:23:33,037 -  DATA - INFO - Data visualisation done\n",
      "2025-01-15 11:23:33,045 - MODEL - INFO - Model Parameters Set\n",
      "2025-01-15 11:23:33,057 - MODEL - INFO - Start Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Input shape: torch.Size([64, 1, 40, 168])\n",
      "  Labels shape: torch.Size([64])\n",
      "EfficientNetCustom(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Swish()\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): MBConv(\n",
      "      (swish): Swish()\n",
      "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEBlock(\n",
      "        (se): Sequential(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (2): Swish()\n",
      "          (3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (expand): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): Swish()\n",
      "      (depthwise): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEBlock(\n",
      "        (se): Sequential(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (2): Swish()\n",
      "          (3): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (pointwise): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): MBConv(\n",
      "      (expand): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): Swish()\n",
      "      (depthwise): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384, bias=False)\n",
      "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEBlock(\n",
      "        (se): Sequential(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (2): Swish()\n",
      "          (3): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (pointwise): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): MBConv(\n",
      "      (expand): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (swish): Swish()\n",
      "      (depthwise): Conv2d(768, 768, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=768, bias=False)\n",
      "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEBlock(\n",
      "        (se): Sequential(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (2): Swish()\n",
      "          (3): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (pointwise): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Swish()\n",
      "    (3): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=37, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e1f4dc6bdc44c3aac80fcb53a386bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Training Loss: 2.73327278710021 Validation Loss: 2.4053237214684486\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "visualize(data[\"test_dataloader\"],data[\"train_dataloader\"])\n",
    "\n",
    "# net = CNN()\n",
    "net = EfficientNetCustom(num_classes=37)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = optim.Adam(net.parameters(), lr=0.003)\n",
    "\n",
    "model = Model()\n",
    "model.set_params(device,net,data,optim,criterion)\n",
    "model.train(epochs=50,lr=0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 20:27:05,236 - MODEL - INFO - Model Saved\n"
     ]
    }
   ],
   "source": [
    "model.save_model('./model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
